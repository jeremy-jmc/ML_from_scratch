## Videos de Introducción: 
* [PyTorch Crash Course](https://www.youtube.com/watch?v=OIenNRt2bjg&t=121s) (Hasta finalizar Neural Network, minuto 38:08)
* [EXTRA: Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi) (Ver hasta el cuarto video. Conocimientos teóricos sobre redes neuronales)

## Questions

- **Definición de Tensor:**
    - **¿Qué es un tensor?**  
      Un tensor es una estructura de datos que generaliza los conceptos de escalares, vectores y matrices a dimensiones superiores. En términos simples, es un contenedor que puede almacenar datos en múltiples dimensiones. Los tensores son fundamentales en el campo del aprendizaje profundo porque representan datos de entrada y salida, así como los parámetros de los modelos.

    - **¿Cuál es la diferencia entre un tensor, una matriz y un vector?**  
      Un vector es una secuencia de números dispuestos en una sola dimensión. Una matriz es una colección de números dispuestos en dos dimensiones, es decir, en filas y columnas. Un tensor es una generalización de estos conceptos y puede tener cualquier número de dimensiones, desde cero (un escalar) hasta múltiples dimensiones (multidimensionales).

    - **¿Cómo se representa un tensor en un código de deep learning?**  
      En código de deep learning, los tensores se suelen representar utilizando librerías como TensorFlow o PyTorch. Por ejemplo, en PyTorch se puede crear un tensor de la siguiente manera:
      ```python
      import torch
      # Crear un tensor de 3x3
      tensor = torch.tensor([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0], [7.0, 8.0, 9.0]])
      ```

- **MLP (Multilayer Perceptron):**
    - **¿Qué es un MLP (Multilayer Perceptron)?**  
      Un Multilayer Perceptron (MLP) es un tipo de red neuronal artificial que consiste en al menos tres capas de nodos: una capa de entrada, una o más capas ocultas, y una capa de salida. Cada nodo o neurona está completamente conectado a las neuronas en la capa siguiente.

    - **¿Cómo funciona un MLP?**  
      Un MLP funciona transmitiendo la información de la capa de entrada a través de las capas ocultas hacia la capa de salida. Cada conexión tiene un peso asociado, y cada neurona tiene una función de activación que transforma la suma ponderada de sus entradas. El objetivo del MLP es aprender los pesos que minimicen el error en la salida respecto a los datos de entrenamiento.

    - **¿Qué rol juegan las capas ocultas en un MLP?**  
      Las capas ocultas en un MLP permiten la modelación de relaciones complejas en los datos. Al introducir no linealidades a través de funciones de activación, las capas ocultas permiten que la red neuronal aprenda patrones complejos y abstracciones en los datos, mejorando así la capacidad del modelo para generalizar y resolver problemas no lineales.

- **Optimizadores:**
    - **¿Qué es un optimizador en deep learning?**  
      Un optimizador en deep learning es un algoritmo que ajusta los parámetros de un modelo, como los pesos y los sesgos, para minimizar una función de pérdida. El optimizador actualiza los parámetros iterativamente para mejorar el rendimiento del modelo durante el entrenamiento.

    - **¿Por qué son importantes los optimizadores?**  
      Los optimizadores son cruciales porque determinan la eficiencia y eficacia del proceso de entrenamiento. Ayudan a encontrar el mínimo de la función de pérdida más rápido y de manera más confiable, lo que resulta en un modelo más preciso y que se entrena en menos tiempo.

    - **Menciona tres ejemplos de optimizadores utilizados comúnmente en deep learning y sus usos.**  
      1. **SGD (Stochastic Gradient Descent):**  
         Usado en tareas de clasificación y regresión, es el optimizador básico que actualiza los parámetros usando un subconjunto aleatorio de datos. Aunque simple, puede ser ineficiente para encontrar mínimos locales.

      2. **Adam (Adaptive Moment Estimation):**  
         Combina las ventajas de dos métodos: el promedio móvil de los gradientes y el promedio móvil de los gradientes cuadrados. Es popular en muchas aplicaciones debido a su eficiencia en manejar problemas con grandes conjuntos de datos y alta dimensionalidad.

      3. **RMSprop (Root Mean Square Propagation):**  
         Adecuado para problemas con gradientes desiguales y ruidosos, RMSprop ajusta la tasa de aprendizaje adaptativamente según el promedio móvil de los gradientes, mejorando la convergencia en problemas de deep learning.

- **Funciones de Pérdida (Loss Functions):**
    - **¿Qué es una función de pérdida en deep learning?**  
      Una función de pérdida en deep learning cuantifica la discrepancia entre las predicciones del modelo y los valores reales esperados. Sirve como guía para los optimizadores, indicando cuánto se debe ajustar el modelo durante el entrenamiento.

    - **¿Por qué es crucial elegir una función de pérdida adecuada?**  
      Elegir una función de pérdida adecuada es esencial porque influye directamente en el comportamiento y el rendimiento del modelo. Una función de pérdida bien elegida puede acelerar la convergencia y mejorar la precisión del modelo, mientras que una elección incorrecta puede llevar a resultados ineficientes o incluso incorrectos.

    - **Menciona tres funciones de pérdida comúnmente utilizadas en deep learning y sus usos.**  
      1. **MSE (Mean Squared Error):**  
         Utilizada principalmente en problemas de regresión, mide el promedio de los cuadrados de las diferencias entre las predicciones y los valores reales.

      2. **Cross-Entropy Loss:**  
         Común en tareas de clasificación, evalúa la diferencia entre la distribución de probabilidad predicha y la real, penalizando predicciones incorrectas más severamente.

      3. **Hinge Loss:**  
         Usada en clasificadores de margen, como las máquinas de soporte vectorial (SVM), evalúa el error en tareas de clasificación marginada, maximizando el margen entre las clases.


## Reto: 
Extender a Linear Regression del curso de Pytorch, para soportar un multiple linear regression. El objetivo es generar un modelo que prediga el precio de una vivienda, según los datos del csv. "linear_regression_dataset.csv"